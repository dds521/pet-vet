# ============================================
# PetVetRAG 公共配置（所有环境共享）
# ============================================

# ============================================
# Nacos 配置
# ============================================
spring:
  cloud:
    nacos:
      discovery:
        server-addr: ${NACOS_SERVER_ADDR:localhost:8848}
        namespace: ${NACOS_NAMESPACE:}
        group: DEFAULT_GROUP
      config:
        server-addr: ${NACOS_SERVER_ADDR:localhost:8848}
        namespace: ${NACOS_NAMESPACE:}
        group: DEFAULT_GROUP
        file-extension: yml
        shared-configs:
          - data-id: pet-vet-rag-common.yml
            group: DEFAULT_GROUP
            refresh: true
  # AI 配置（所有环境公共）
  # 支持 OpenAI、DeepSeek 和 xAI Grok
  # 推荐使用 DeepSeek（价格更便宜，国内访问更稳定）或 Grok（性能优秀）
  ai:
    # AI 提供商类型：openai、deepseek 或 grok（默认使用 deepseek）
    provider:
      type: ${AI_PROVIDER_TYPE:deepseek}
    
    # OpenAI 配置
    openai:
      api-key: ${OPENAI_API_KEY:}
      chat:
        options:
          model: ${OPENAI_MODEL:gpt-4o}
          temperature: ${OPENAI_TEMPERATURE:0.7}
    
    # DeepSeek 配置（推荐）
    # DeepSeek 使用 OpenAI 兼容的 API，价格更便宜，国内访问更稳定
    # 申请地址：https://platform.deepseek.com/
    # ⚠️ 注意：API Key 必须通过环境变量 DEEPSEEK_API_KEY 配置，不要直接写在配置文件中
    deepseek:
      api-key: ${DEEPSEEK_API_KEY:}
      base-url: ${DEEPSEEK_BASE_URL:https://api.deepseek.com}
      chat:
        options:
          model: ${DEEPSEEK_MODEL:deepseek-chat}
          temperature: ${DEEPSEEK_TEMPERATURE:0.7}
    
    # xAI Grok 配置
    # Grok 是 xAI 开发的 AI 模型，使用 OpenAI 兼容的 API
    # 申请地址：https://x.ai/
    # ⚠️ 注意：API Key 必须通过环境变量 GROK_API_KEY 配置，不要直接写在配置文件中
    grok:
      api-key: ${GROK_API_KEY:}
      base-url: ${GROK_BASE_URL:https://api.x.ai/v1}
      chat:
        options:
          model: ${GROK_MODEL:grok-4-latest}
          temperature: ${GROK_TEMPERATURE:0.7}

# ============================================
# RAG 配置
# ============================================
rag:
  retrieval:
    # 默认最大检索结果数
    default-max-results: 10
    # 默认最小相似度分数（0.0-1.0）
    default-min-score: 0.7
    # 默认上下文窗口大小（用于生成答案时包含的上下文chunk数量）
    default-context-window-size: 5
  generation:
    # 是否默认启用生成
    default-enable-generation: true
    # 默认模型名称（openai, ollama等）
    default-model-name: gpt-3.5-turbo
    # 生成温度（0.0-2.0，越高越随机）
    temperature: 0.7
    # 最大token数
    max-tokens: 1000
    # 提示词模板
    prompt-template: |
      基于以下上下文信息回答用户的问题。如果上下文中没有相关信息，请说明无法从提供的信息中找到答案。
      
      上下文信息：
      {context}
      
      用户问题：{question}
      
      请提供详细、准确的答案：

# ============================================
# 向量数据库配置（复用embedding模块的配置）
# ============================================
# 注意：RAG模块需要访问向量数据库，可以通过Feign调用embedding服务
# 或者直接配置向量数据库连接（如果需要在RAG模块中直接访问）
